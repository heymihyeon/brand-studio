---
title: 'AIDA Project Task Execution System'
read_only: true
type: 'command'
version: '1.0.0'
---

# 🚀 '/execute' - Execute planned tasks with full implementation and verification

**IMPORTANT**: All user-facing messages, questions, and results must be displayed in Korean (한국어).

Purpose: Execute tasks generated by /plan command with complete implementation and verification
User Instruction: $ARGUMENTS

## 📋 Execution Modes
- `/execute` - Execute ALL tasks from the most recent plan
- `/execute plan-task.md` - Execute tasks from specified plan file
- `/execute T307` - Execute single task T307
- `/execute T307-T310` - Execute tasks T307 through T310 sequentially

## ⚠️ CRITICAL CONSTRAINTS ⚠️

### Quality Enforcement Rules
1. **NEVER proceed to next task if quality standards are not met**
2. **Maximum 3 retry attempts** for failed tasks with deep analysis
3. **STOP execution and report** if task fails after 3 attempts
4. **Quality standards are NON-NEGOTIABLE**

### Execution Prerequisites
BEFORE executing any task, verify:
1. Task IDs exist and are valid (generated by /plan)
2. All prerequisite tasks are completed
3. Required resources and dependencies are available
4. All tests are passing in current state

### Security & Quality Rules
Apply all rules from {project-root}/CLAUDE.md:
1. TypeScript Safety Rules (Section 2)
2. Security Rules (Section 4)
3. Kubernetes Command Safety (Section 5)
4. Build Verification (Section 1)
5. All project rules as specified in CLAUDE.md

## Step 1: Task Validation & Preparation

### 1.1 Parse Execution Mode
```
Determine execution mode:
- No arguments → Execute ALL tasks from most recent plan
- *.md file → Load tasks from specified plan file  
- T### → Execute single task
- T###-T### → Execute task range
```

### 1.2 Load Task Definitions
```
TASK LOADING:
━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━
IF no arguments:
  → Load most recent /plan output
IF plan file specified:
  → Parse tasks from provided .md file
IF task IDs specified:
  → Validate task IDs exist in plan
━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━
```

### 1.3 Dependency Check
```
DEPENDENCY VERIFICATION:
━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━
□ Verify all prerequisites completed
□ Check resource availability
□ Confirm environment readiness
□ Validate required permissions
━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━
```

### 1.4 Pre-execution State
```bash
# Capture initial state
npm test -- --passWithNoTests
npm run lint -- --quiet
```

## Step 2: Task Execution Engine

### 2.1 For Each Task in Sequence

```
EXECUTING TASK: [T###]
━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━
[Display task title and category]
시작 시간: [timestamp]
━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━
```

### 2.2 File Operations

#### CREATE File Operation
```typescript
// Creating: [file path]
// Verify directory exists
// Write complete file content
// Set appropriate permissions
```

#### MODIFY File Operation
```typescript
// Modifying: [file path]
// Read current content
// Apply modifications at specified lines
// Preserve file formatting
// Create backup if critical file
```

#### DELETE File Operation
```typescript
// Deleting: [file path]
// Verify file exists
// Check for dependencies
// Remove file
// Clean up empty directories
```

### 2.3 Implementation Execution

For each file operation in task:
1. **Read task implementation code**
2. **Verify target path exists/create directories**
3. **Execute file operation (CREATE/MODIFY/DELETE)**
4. **Verify operation success**
5. **Run immediate syntax check**

```
파일 작업 실행:
━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━
✅ Created: src/api/routes/metrics.ts
✅ Modified: src/api/routes/index.ts (2 changes)
✅ Syntax check passed
━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━
```

### 2.4 Incremental Verification with Quality Gates

After EACH task completion:
```bash
# Quick verification (< 30 seconds)
npm run build -- --incremental
npm test -- --passWithNoTests --testPathPattern=[affected]
```

### 2.5 Task-Level Quality Enforcement
```
FOR each task:
  ATTEMPT = 1
  SUCCESS = false
  
  WHILE ATTEMPT <= 3 AND NOT SUCCESS:
    # Execute task implementation
    EXECUTE task operations
    
    # Verify quality standards
    RUN quick build check
    RUN affected tests
    CHECK type safety
    
    IF quality standards met:
      SUCCESS = true
      echo "✅ 태스크 T### 완료"
    ELSE:
      IF ATTEMPT < 3:
        echo "⚠️ 태스크 품질 기준 미달 - 재시도 ($ATTEMPT/3)"
        ANALYZE failure reason
        APPLY corrective actions
        ATTEMPT++
      ELSE:
        echo "❌ 태스크 T### 실패 (3회 시도)"
        STOP all execution
        GENERATE failure report
        EXIT
```

## Step 3: Task-Specific Handlers

### 3.1 Development Tasks
```
DEVELOPMENT TASK EXECUTION:
1. Create/modify source files
2. Update imports and exports
3. Verify TypeScript compilation
4. Check for circular dependencies
5. Update related test files
```

### 3.2 Testing Tasks
```
TESTING TASK EXECUTION:
1. Create test files
2. Implement test cases
3. Run specific test suite
4. Verify coverage targets
5. Update test documentation
```

### 3.3 Configuration Tasks
```
CONFIGURATION TASK EXECUTION:
1. Create/update config files
2. Validate configuration syntax
3. Check environment variables
4. Test configuration loading
5. Update .gitignore if needed
```

## Step 4: Progressive Build Verification

### 4.1 After Each Task Group (e.g., T307-T309)
```bash
echo "━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━"
echo "🔨 중간 빌드 검증 실행 중..."
echo "━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━"

# TypeScript Compilation
npm run build
# → Must succeed with 0 errors

# Linting
npm run lint
# → Must have 0 errors

# Type Checking  
npm run typecheck
# → Must have 0 errors

# Test Affected Modules
npm test -- --testPathPattern="(metrics|database|integration)"
# → All must pass
```

### 4.2 Quality Verification with Retry Logic
```
VERIFICATION_ATTEMPT = 1
MAX_ATTEMPTS = 3

WHILE verification fails AND VERIFICATION_ATTEMPT <= MAX_ATTEMPTS:
  
  IF VERIFICATION_ATTEMPT > 1:
    echo "⚠️ 품질 기준 미달 - 재시도 중 ($VERIFICATION_ATTEMPT/$MAX_ATTEMPTS)"
    echo "🤔 문제를 깊이 분석하고 해결책을 찾는 중..."
    
    # Deep Analysis Phase
    1. Analyze exact error messages
    2. Review implementation against requirements
    3. Check for missing imports or dependencies
    4. Verify type definitions
    5. Review test coverage gaps
    6. Identify root cause
    
    # Fix Implementation
    - Apply targeted fixes based on analysis
    - Update affected files
    - Ensure no regression
  
  # Run Verification
  RUN build verification
  RUN test suite
  RUN coverage check
  
  IF all checks pass:
    echo "✅ 품질 기준 달성!"
    BREAK
  ELSE:
    VERIFICATION_ATTEMPT++
    
    IF VERIFICATION_ATTEMPT > MAX_ATTEMPTS:
      echo "❌ 3번의 시도 후에도 품질 기준 미달"
      echo "📋 실패 상세 보고서:"
      - List all failing checks
      - Show error details
      - Provide diagnostic information
      STOP EXECUTION
      REPORT TO USER
```

### 4.3 Error Analysis Framework
```
품질 검증 실패 시 분석 체크리스트:
━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━
□ TypeScript 에러 상세 분석
  - Missing type definitions?
  - Incorrect import paths?
  - Type mismatches?
  
□ 테스트 실패 원인 분석
  - Test data issues?
  - Mock configuration?
  - Async handling?
  
□ 린트 에러 분석
  - Code style violations?
  - Unused variables?
  - Missing error handling?
  
□ 의존성 문제 확인
  - Package versions?
  - Peer dependencies?
  - Module resolution?
━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━
```

## Step 5: Final Comprehensive Verification

### 5.1 Complete Build & Test Suite
```bash
echo "━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━"
echo "🏁 최종 검증 실행 중..."
echo "━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━"

# 1. Clean Build
rm -rf dist/
npm run build

# 2. Full Test Suite
npm test

# 3. Coverage Check
npm run coverage
# → Overall: 80%+ required
# → Core modules: 90%+ required

# 4. Integration Tests
npm test tests/integration/

# 5. Start Development Server
npm run dev &
DEV_PID=$!
sleep 5

# 6. Health Check
curl -f http://localhost:3000/api/health/health || exit 1

# 7. API Endpoint Tests
curl -f http://localhost:3000/api/metrics/llm-usage || exit 1
curl -f http://localhost:3000/api/metrics/performance || exit 1

# 8. Stop Dev Server
kill $DEV_PID

# 9. Docker Build & Run
npm run docker:build
docker-compose up -d
sleep 10

# 10. Docker Health Check
docker ps | grep aida-mvp
curl -f http://localhost:3000/api/health/health || exit 1

# 11. Performance Test (3-minute check)
./scripts/performance-test.sh
```

### 5.2 Rollback Procedure
If critical failures occur after 3 attempts:
```bash
# Automatic rollback on quality failure
echo "❌ 품질 기준 미달로 인한 실행 중단"
git stash save "execution-backup-$(date +%Y%m%d-%H%M%S)"
git checkout .
echo "⚠️ 변경사항이 백업되고 롤백되었습니다"
echo "📋 실패 분석 보고서를 생성하는 중..."

# Generate detailed failure report
cat > failure-report-$(date +%Y%m%d-%H%M%S).md << EOF
# 실행 실패 보고서

## 실패한 태스크: T###
## 시도 횟수: 3/3
## 실패 원인:
- [상세 에러 메시지]
- [실패한 품질 기준]
- [영향받은 파일]

## 분석된 문제점:
- [근본 원인 분석]
- [의존성 문제]
- [환경 설정 이슈]

## 권장 조치사항:
1. [수동 수정 필요 사항]
2. [환경 설정 변경]
3. [추가 조사 필요 영역]
EOF
```

## Step 6: Execution Report Generation

### 6.1 Task Execution Summary
```markdown
## 📊 태스크 실행 결과 요약

### 실행된 태스크
- [T###] ✅ 제목 (소요시간: X분)
- [T###] ✅ 제목 (소요시간: X분)
- [T###] ❌ 제목 (실패 - 이유)

### 파일 변경사항
**생성된 파일:** X개
- path/to/file1.ts
- path/to/file2.ts

**수정된 파일:** X개
- path/to/file3.ts (X lines changed)
- path/to/file4.ts (X lines changed)

**삭제된 파일:** X개
- path/to/old-file.ts
```

### 6.2 Quality Metrics Report
```markdown
## 📈 품질 지표

### 테스트 커버리지
- 전체: XX% (목표: 80%)
- 핵심 모듈: XX% (목표: 90%)
- 새 코드: XX% (목표: 95%)

### 코드 품질
- TypeScript 오류: 0
- Lint 경고: X개
- 순환 의존성: 0

### 성능 지표
- 빌드 시간: X초
- 테스트 실행 시간: X초
- Docker 이미지 크기: XXX MB
- 애플리케이션 시작 시간: X초
```

### 6.3 Final Status Report
```markdown
## ✅ 최종 실행 상태

### 빌드 & 테스트
- ✅ TypeScript 컴파일: 성공 (0 errors)
- ✅ Lint: 통과 (0 errors, X warnings)
- ✅ 테스트: X/X 통과
- ✅ 커버리지: XX% (목표 달성)

### 품질 보증
- 총 재시도 횟수: X회
- 첫 시도 성공률: XX%
- 최종 성공률: 100%

### 애플리케이션
- ✅ 개발 서버: http://localhost:3000 정상 작동
- ✅ Health Check: 정상
- ✅ API 엔드포인트: 모두 정상

### Docker
- ✅ 이미지 빌드: 성공
- ✅ 컨테이너 실행: 정상
- ✅ Health Check: 통과

### 실행 요약
- 전체 태스크: X개
- 성공: X개
- 재시도 후 성공: X개
- 실패: 0개

### 📝 다음 단계
1. 코드 리뷰 요청
2. PR 생성
3. 배포 준비
```

## Step 7: Post-Execution Actions

### 7.1 Git Commit Preparation (Optional)
```bash
# If all tasks succeeded, prepare commit
echo "feat: implement tasks T###-T### 

- Add LLM usage monitoring API
- Implement database integration tests  
- Configure Docker and environment setup
- Complete build verification

Co-Authored-By: Claude <noreply@anthropic.com>"
```

### 7.2 Cleanup
```bash
# Remove temporary files
rm -f *.tmp *.backup

# Prune Docker resources
docker system prune -f

# Clear test databases
rm -f ./data/test-*.db
```

## 💡 Usage Examples

```bash
# Execute all tasks from most recent plan
/execute

# Execute tasks from specific plan file
/execute project-refactoring-plan.md

# Execute single task
/execute T307

# Execute task range
/execute T307-T310
```

## 🔄 Execution Flow with Quality Gates

1. **Task Loading** → 2. **Pre-validation** → 3. **Task Execution** → 4. **Quality Check** → 5. **Retry if Failed (Max 3)** → 6. **Next Task or Stop** → 7. **Final Report**

### Quality Gate Process
```
┌─────────────────┐
│  Execute Task   │
└────────┬────────┘
         ↓
┌─────────────────┐
│ Quality Check   │
└────────┬────────┘
         ↓
    ┌────────┐
    │ Pass?  │──Yes──→ Next Task
    └────┬───┘
         │ No
         ↓
    ┌────────────┐
    │ Retry < 3? │──No──→ STOP & Report
    └────┬───────┘
         │ Yes
         ↓
┌─────────────────┐
│  Deep Analysis  │
│   & Fix Retry   │
└─────────────────┘
```

## Output Format

```
═══════════════════════════════════════════════════
태스크 실행 완료
═══════════════════════════════════════════════════
실행 범위: T### - T###
총 실행 시간: XX분 XX초
성공률: XX% (X/X 태스크)

주요 성과:
✅ 모든 태스크 구현 완료
✅ 테스트 커버리지 목표 달성
✅ 빌드 및 타입 체크 통과
✅ Docker 환경 정상 작동

상세 보고서는 위 섹션을 참조하세요.
═══════════════════════════════════════════════════
```

## Error Recovery Procedures

### Build Failures
1. Check TypeScript errors in detail
2. Verify import paths
3. Check for missing dependencies
4. Review recent changes

### Test Failures  
1. Run failed tests in isolation
2. Check test data and mocks
3. Verify environment setup
4. Review implementation logic

### Docker Issues
1. Check Dockerfile syntax
2. Verify port availability
3. Review volume mounts
4. Check resource limits

## Critical Reminders

1. **NEVER skip quality verification** - it ensures code quality
2. **NEVER proceed if quality standards not met** - stop and fix
3. **ALWAYS retry with deep analysis** - up to 3 attempts
4. **STOP execution after 3 failures** - report to user
5. **VERIFY each task independently** - maintain high standards
6. **DOCUMENT all retry attempts** - for troubleshooting
7. **BACKUP before major changes** - enable safe rollback